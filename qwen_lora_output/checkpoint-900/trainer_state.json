{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.07480674923115285,
  "eval_steps": 500,
  "global_step": 900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008311861025683651,
      "grad_norm": 40.58424377441406,
      "learning_rate": 0.00019997229379658106,
      "loss": 8.1695,
      "step": 10
    },
    {
      "epoch": 0.0016623722051367302,
      "grad_norm": 32.428810119628906,
      "learning_rate": 0.0001999168813897432,
      "loss": 6.5936,
      "step": 20
    },
    {
      "epoch": 0.0024935583077050952,
      "grad_norm": 32.22614288330078,
      "learning_rate": 0.00019986701022358907,
      "loss": 6.0244,
      "step": 30
    },
    {
      "epoch": 0.0033247444102734603,
      "grad_norm": 26.955068588256836,
      "learning_rate": 0.0001998115978167512,
      "loss": 5.4957,
      "step": 40
    },
    {
      "epoch": 0.004155930512841825,
      "grad_norm": 29.929759979248047,
      "learning_rate": 0.0001997561854099133,
      "loss": 5.469,
      "step": 50
    },
    {
      "epoch": 0.0049871166154101905,
      "grad_norm": 19.519731521606445,
      "learning_rate": 0.0001997007730030754,
      "loss": 5.0418,
      "step": 60
    },
    {
      "epoch": 0.005818302717978555,
      "grad_norm": 21.40792465209961,
      "learning_rate": 0.0001996453605962375,
      "loss": 5.13,
      "step": 70
    },
    {
      "epoch": 0.006649488820546921,
      "grad_norm": 22.05910301208496,
      "learning_rate": 0.00019958994818939963,
      "loss": 5.0812,
      "step": 80
    },
    {
      "epoch": 0.007480674923115285,
      "grad_norm": 17.48219108581543,
      "learning_rate": 0.00019953453578256173,
      "loss": 4.921,
      "step": 90
    },
    {
      "epoch": 0.00831186102568365,
      "grad_norm": 22.203372955322266,
      "learning_rate": 0.00019947912337572383,
      "loss": 4.5098,
      "step": 100
    },
    {
      "epoch": 0.009143047128252016,
      "grad_norm": 26.987581253051758,
      "learning_rate": 0.00019942371096888596,
      "loss": 4.6903,
      "step": 110
    },
    {
      "epoch": 0.009974233230820381,
      "grad_norm": 17.327678680419922,
      "learning_rate": 0.00019936829856204806,
      "loss": 4.5286,
      "step": 120
    },
    {
      "epoch": 0.010805419333388746,
      "grad_norm": 17.699270248413086,
      "learning_rate": 0.00019931288615521016,
      "loss": 4.4983,
      "step": 130
    },
    {
      "epoch": 0.01163660543595711,
      "grad_norm": 18.489322662353516,
      "learning_rate": 0.00019925747374837226,
      "loss": 4.3178,
      "step": 140
    },
    {
      "epoch": 0.012467791538525477,
      "grad_norm": 19.48923110961914,
      "learning_rate": 0.00019920206134153439,
      "loss": 3.7664,
      "step": 150
    },
    {
      "epoch": 0.013298977641093841,
      "grad_norm": 15.310059547424316,
      "learning_rate": 0.00019914664893469649,
      "loss": 3.8018,
      "step": 160
    },
    {
      "epoch": 0.014130163743662206,
      "grad_norm": 17.193960189819336,
      "learning_rate": 0.0001990912365278586,
      "loss": 3.3423,
      "step": 170
    },
    {
      "epoch": 0.01496134984623057,
      "grad_norm": 17.13886070251465,
      "learning_rate": 0.00019903582412102072,
      "loss": 3.3869,
      "step": 180
    },
    {
      "epoch": 0.015792535948798935,
      "grad_norm": 18.822059631347656,
      "learning_rate": 0.00019898041171418282,
      "loss": 3.1874,
      "step": 190
    },
    {
      "epoch": 0.0166237220513673,
      "grad_norm": 22.45027732849121,
      "learning_rate": 0.00019892499930734492,
      "loss": 2.8665,
      "step": 200
    },
    {
      "epoch": 0.017454908153935668,
      "grad_norm": 15.807849884033203,
      "learning_rate": 0.00019886958690050704,
      "loss": 2.4057,
      "step": 210
    },
    {
      "epoch": 0.018286094256504033,
      "grad_norm": 15.761362075805664,
      "learning_rate": 0.00019881417449366915,
      "loss": 2.2139,
      "step": 220
    },
    {
      "epoch": 0.019117280359072397,
      "grad_norm": 17.534629821777344,
      "learning_rate": 0.00019875876208683125,
      "loss": 2.3768,
      "step": 230
    },
    {
      "epoch": 0.019948466461640762,
      "grad_norm": 17.097393035888672,
      "learning_rate": 0.00019870334967999335,
      "loss": 2.1183,
      "step": 240
    },
    {
      "epoch": 0.020779652564209126,
      "grad_norm": 15.901248931884766,
      "learning_rate": 0.00019864793727315547,
      "loss": 2.2904,
      "step": 250
    },
    {
      "epoch": 0.02161083866677749,
      "grad_norm": 17.334548950195312,
      "learning_rate": 0.00019859252486631758,
      "loss": 1.8424,
      "step": 260
    },
    {
      "epoch": 0.022442024769345856,
      "grad_norm": 13.628207206726074,
      "learning_rate": 0.00019853711245947968,
      "loss": 1.6308,
      "step": 270
    },
    {
      "epoch": 0.02327321087191422,
      "grad_norm": 19.151784896850586,
      "learning_rate": 0.0001984817000526418,
      "loss": 1.7767,
      "step": 280
    },
    {
      "epoch": 0.024104396974482585,
      "grad_norm": 13.167598724365234,
      "learning_rate": 0.0001984262876458039,
      "loss": 1.8194,
      "step": 290
    },
    {
      "epoch": 0.024935583077050953,
      "grad_norm": 14.654765129089355,
      "learning_rate": 0.000198370875238966,
      "loss": 1.9239,
      "step": 300
    },
    {
      "epoch": 0.025766769179619318,
      "grad_norm": 14.919727325439453,
      "learning_rate": 0.0001983154628321281,
      "loss": 1.9203,
      "step": 310
    },
    {
      "epoch": 0.026597955282187682,
      "grad_norm": 12.919363021850586,
      "learning_rate": 0.00019826005042529023,
      "loss": 2.1604,
      "step": 320
    },
    {
      "epoch": 0.027429141384756047,
      "grad_norm": 15.171833038330078,
      "learning_rate": 0.00019820463801845236,
      "loss": 1.8141,
      "step": 330
    },
    {
      "epoch": 0.028260327487324412,
      "grad_norm": 17.67120361328125,
      "learning_rate": 0.00019814922561161444,
      "loss": 1.8344,
      "step": 340
    },
    {
      "epoch": 0.029091513589892776,
      "grad_norm": 12.165955543518066,
      "learning_rate": 0.00019809381320477656,
      "loss": 1.7545,
      "step": 350
    },
    {
      "epoch": 0.02992269969246114,
      "grad_norm": 12.908447265625,
      "learning_rate": 0.00019803840079793866,
      "loss": 1.6829,
      "step": 360
    },
    {
      "epoch": 0.030753885795029506,
      "grad_norm": 9.30648136138916,
      "learning_rate": 0.0001979829883911008,
      "loss": 1.4865,
      "step": 370
    },
    {
      "epoch": 0.03158507189759787,
      "grad_norm": 16.777860641479492,
      "learning_rate": 0.0001979275759842629,
      "loss": 1.5661,
      "step": 380
    },
    {
      "epoch": 0.03241625800016624,
      "grad_norm": 14.414044380187988,
      "learning_rate": 0.000197872163577425,
      "loss": 1.5601,
      "step": 390
    },
    {
      "epoch": 0.0332474441027346,
      "grad_norm": 13.789533615112305,
      "learning_rate": 0.00019781675117058712,
      "loss": 1.4959,
      "step": 400
    },
    {
      "epoch": 0.03407863020530297,
      "grad_norm": 15.775552749633789,
      "learning_rate": 0.0001977613387637492,
      "loss": 1.3315,
      "step": 410
    },
    {
      "epoch": 0.034909816307871336,
      "grad_norm": 15.758426666259766,
      "learning_rate": 0.00019770592635691132,
      "loss": 1.6078,
      "step": 420
    },
    {
      "epoch": 0.0357410024104397,
      "grad_norm": 20.526803970336914,
      "learning_rate": 0.00019765051395007342,
      "loss": 1.4744,
      "step": 430
    },
    {
      "epoch": 0.036572188513008065,
      "grad_norm": 13.144030570983887,
      "learning_rate": 0.00019759510154323555,
      "loss": 1.5023,
      "step": 440
    },
    {
      "epoch": 0.037403374615576426,
      "grad_norm": 13.956729888916016,
      "learning_rate": 0.00019753968913639765,
      "loss": 1.4337,
      "step": 450
    },
    {
      "epoch": 0.038234560718144794,
      "grad_norm": 12.458641052246094,
      "learning_rate": 0.00019748427672955975,
      "loss": 1.1563,
      "step": 460
    },
    {
      "epoch": 0.039065746820713156,
      "grad_norm": 15.867718696594238,
      "learning_rate": 0.00019742886432272188,
      "loss": 1.5371,
      "step": 470
    },
    {
      "epoch": 0.039896932923281524,
      "grad_norm": 13.827683448791504,
      "learning_rate": 0.00019737345191588396,
      "loss": 1.4896,
      "step": 480
    },
    {
      "epoch": 0.040728119025849885,
      "grad_norm": 12.160133361816406,
      "learning_rate": 0.00019731803950904608,
      "loss": 1.2966,
      "step": 490
    },
    {
      "epoch": 0.04155930512841825,
      "grad_norm": 14.774539947509766,
      "learning_rate": 0.00019726262710220818,
      "loss": 1.2865,
      "step": 500
    },
    {
      "epoch": 0.04239049123098662,
      "grad_norm": 13.052340507507324,
      "learning_rate": 0.0001972072146953703,
      "loss": 1.2649,
      "step": 510
    },
    {
      "epoch": 0.04322167733355498,
      "grad_norm": 12.405893325805664,
      "learning_rate": 0.0001971518022885324,
      "loss": 1.0955,
      "step": 520
    },
    {
      "epoch": 0.04405286343612335,
      "grad_norm": 15.355608940124512,
      "learning_rate": 0.0001970963898816945,
      "loss": 1.3658,
      "step": 530
    },
    {
      "epoch": 0.04488404953869171,
      "grad_norm": 12.68369197845459,
      "learning_rate": 0.00019704097747485664,
      "loss": 1.3287,
      "step": 540
    },
    {
      "epoch": 0.04571523564126008,
      "grad_norm": 12.962346076965332,
      "learning_rate": 0.00019698556506801874,
      "loss": 1.2848,
      "step": 550
    },
    {
      "epoch": 0.04654642174382844,
      "grad_norm": 16.527379989624023,
      "learning_rate": 0.00019693015266118084,
      "loss": 1.4715,
      "step": 560
    },
    {
      "epoch": 0.04737760784639681,
      "grad_norm": 12.098690032958984,
      "learning_rate": 0.00019687474025434297,
      "loss": 1.2894,
      "step": 570
    },
    {
      "epoch": 0.04820879394896517,
      "grad_norm": 14.453927040100098,
      "learning_rate": 0.00019681932784750507,
      "loss": 1.2849,
      "step": 580
    },
    {
      "epoch": 0.04903998005153354,
      "grad_norm": 17.015079498291016,
      "learning_rate": 0.00019676391544066717,
      "loss": 1.3777,
      "step": 590
    },
    {
      "epoch": 0.049871166154101906,
      "grad_norm": 14.99071979522705,
      "learning_rate": 0.00019670850303382927,
      "loss": 1.2281,
      "step": 600
    },
    {
      "epoch": 0.05070235225667027,
      "grad_norm": 15.679591178894043,
      "learning_rate": 0.0001966530906269914,
      "loss": 1.1587,
      "step": 610
    },
    {
      "epoch": 0.051533538359238636,
      "grad_norm": 21.64603614807129,
      "learning_rate": 0.0001965976782201535,
      "loss": 1.2842,
      "step": 620
    },
    {
      "epoch": 0.052364724461807,
      "grad_norm": 14.74042797088623,
      "learning_rate": 0.0001965422658133156,
      "loss": 1.4599,
      "step": 630
    },
    {
      "epoch": 0.053195910564375365,
      "grad_norm": 12.662609100341797,
      "learning_rate": 0.00019648685340647773,
      "loss": 1.2808,
      "step": 640
    },
    {
      "epoch": 0.054027096666943726,
      "grad_norm": 11.602177619934082,
      "learning_rate": 0.00019643144099963983,
      "loss": 1.4534,
      "step": 650
    },
    {
      "epoch": 0.054858282769512094,
      "grad_norm": 10.813095092773438,
      "learning_rate": 0.00019637602859280193,
      "loss": 1.2077,
      "step": 660
    },
    {
      "epoch": 0.055689468872080455,
      "grad_norm": 13.706011772155762,
      "learning_rate": 0.00019632061618596403,
      "loss": 1.4279,
      "step": 670
    },
    {
      "epoch": 0.056520654974648823,
      "grad_norm": 13.069347381591797,
      "learning_rate": 0.00019626520377912616,
      "loss": 1.2779,
      "step": 680
    },
    {
      "epoch": 0.05735184107721719,
      "grad_norm": 7.74382209777832,
      "learning_rate": 0.00019620979137228826,
      "loss": 1.159,
      "step": 690
    },
    {
      "epoch": 0.05818302717978555,
      "grad_norm": 11.276467323303223,
      "learning_rate": 0.00019615437896545036,
      "loss": 1.3431,
      "step": 700
    },
    {
      "epoch": 0.05901421328235392,
      "grad_norm": 13.244213104248047,
      "learning_rate": 0.0001960989665586125,
      "loss": 1.2106,
      "step": 710
    },
    {
      "epoch": 0.05984539938492228,
      "grad_norm": 11.590180397033691,
      "learning_rate": 0.0001960435541517746,
      "loss": 1.3857,
      "step": 720
    },
    {
      "epoch": 0.06067658548749065,
      "grad_norm": 11.790502548217773,
      "learning_rate": 0.0001959881417449367,
      "loss": 1.0037,
      "step": 730
    },
    {
      "epoch": 0.06150777159005901,
      "grad_norm": 11.375626564025879,
      "learning_rate": 0.00019593272933809882,
      "loss": 1.2309,
      "step": 740
    },
    {
      "epoch": 0.06233895769262738,
      "grad_norm": 9.692102432250977,
      "learning_rate": 0.00019587731693126092,
      "loss": 1.2307,
      "step": 750
    },
    {
      "epoch": 0.06317014379519574,
      "grad_norm": 11.609149932861328,
      "learning_rate": 0.00019582190452442305,
      "loss": 1.3369,
      "step": 760
    },
    {
      "epoch": 0.06400132989776411,
      "grad_norm": 14.979608535766602,
      "learning_rate": 0.00019576649211758512,
      "loss": 1.0814,
      "step": 770
    },
    {
      "epoch": 0.06483251600033248,
      "grad_norm": 9.706363677978516,
      "learning_rate": 0.00019571107971074725,
      "loss": 1.0173,
      "step": 780
    },
    {
      "epoch": 0.06566370210290084,
      "grad_norm": 10.728867530822754,
      "learning_rate": 0.00019565566730390935,
      "loss": 1.4589,
      "step": 790
    },
    {
      "epoch": 0.0664948882054692,
      "grad_norm": 11.61741828918457,
      "learning_rate": 0.00019560025489707145,
      "loss": 1.2705,
      "step": 800
    },
    {
      "epoch": 0.06732607430803757,
      "grad_norm": 7.832098484039307,
      "learning_rate": 0.00019554484249023358,
      "loss": 1.1301,
      "step": 810
    },
    {
      "epoch": 0.06815726041060594,
      "grad_norm": 8.713362693786621,
      "learning_rate": 0.00019548943008339568,
      "loss": 1.3762,
      "step": 820
    },
    {
      "epoch": 0.0689884465131743,
      "grad_norm": 13.007731437683105,
      "learning_rate": 0.0001954340176765578,
      "loss": 1.0524,
      "step": 830
    },
    {
      "epoch": 0.06981963261574267,
      "grad_norm": 14.922541618347168,
      "learning_rate": 0.00019537860526971988,
      "loss": 1.1149,
      "step": 840
    },
    {
      "epoch": 0.07065081871831103,
      "grad_norm": 15.606546401977539,
      "learning_rate": 0.000195323192862882,
      "loss": 1.4272,
      "step": 850
    },
    {
      "epoch": 0.0714820048208794,
      "grad_norm": 15.1175537109375,
      "learning_rate": 0.00019526778045604414,
      "loss": 1.0267,
      "step": 860
    },
    {
      "epoch": 0.07231319092344776,
      "grad_norm": 12.72982120513916,
      "learning_rate": 0.0001952123680492062,
      "loss": 1.0814,
      "step": 870
    },
    {
      "epoch": 0.07314437702601613,
      "grad_norm": 10.486427307128906,
      "learning_rate": 0.00019515695564236834,
      "loss": 1.028,
      "step": 880
    },
    {
      "epoch": 0.07397556312858448,
      "grad_norm": 10.996407508850098,
      "learning_rate": 0.00019510154323553044,
      "loss": 0.9878,
      "step": 890
    },
    {
      "epoch": 0.07480674923115285,
      "grad_norm": 11.62549114227295,
      "learning_rate": 0.00019504613082869257,
      "loss": 1.0634,
      "step": 900
    }
  ],
  "logging_steps": 10,
  "max_steps": 36093,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 30,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.388777305030246e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
